{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALLY Quickstart\n",
    "\n",
    "In this notebook, we are going to run through some of the common tasks for creating data labeling agents with ALLY. In this example, we're going to create a data labeling agent for a text classification task - labeling our text samples as either \"Subjective or \"Objective\" statements. \n",
    "\n",
    "This agent will be LLM-based, so we will use [OpenAI's API](https://platform.openai.com/). You will to generate an API key and set it as an environment variable as follows: \n",
    "\n",
    "\n",
    "Now, let's begin. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Creation\n",
    "First, let's use a dataset of product reviews stored in pandas dataframe. This will help us manage our data as we add more attributes, like predictions and labels for subjectivity and objectivity over time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame([\n",
    "  [\"The mic is great.\", \"Subjective\"],\n",
    "  [\"Will order from them again!\", \"Subjective\"],\n",
    "  [\"Not loud enough and doesn't turn on like it should.\", \"Objective\"],\n",
    "  [\"The phone doesn't seem to accept anything except CBR mp3s\", \"Objective\"],\n",
    "  [\"All three broke within two months of use.\", \"Objective\"]\n",
    "], columns=[\"text\", \"ground_truth\"])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We instantiate the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from ally.environments.base import StaticEnvironment\n",
    "\n",
    "\n",
    "env = environment=StaticEnvironment(\n",
    "  df=df,\n",
    "  ground_truth_columns={'predictions': 'ground_truth'}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Agent\n",
    "\n",
    "To create Agent, we need to to define 2 things:\n",
    "\n",
    "**Skills** - Agent's abilities are defined as _Skills_. Each agent can possess many different skills. In our case, this agent only has one labeling skill, to produce a classification of Subjective or Objective for a given piece of text.  To define this skill, we will leverage an LLM, passing it instructions and the set of labeles we expect to receive back. \n",
    "\n",
    "**Environment** - that is where the Agent receives ground truth signal to improve its skill. Since we already created ground truth dataset, we can simply refer to the column from the dataframe. In the real world scenario, you may consider using a different environment where ground truth signal can be obtained asynchoronously by gathering real human feedback during agent's learning phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print\n",
    "\n",
    "from ally.agents.base import Agent\n",
    "from ally.runtimes.openai import OpenAIRuntime\n",
    "from ally.skills.collection.classification import ClassificationSkill\n",
    "from app.core.settings import settings\n",
    "\n",
    "\n",
    "agent = Agent(\n",
    "    # define the agent's labeling skill that should classify text onto 2 categories\n",
    "    skills=ClassificationSkill(\n",
    "      name='subjectivity_detection',\n",
    "      description='Understanding subjective and objective statements from text.',\n",
    "      instruction_template='Classify a product review as either expressing \"Subjective\" or \"Objective\" statements.',\n",
    "      input_template='Review: {text}',\n",
    "    ),\n",
    "    \n",
    "    # basic environment extracts ground truth signal from the input records\n",
    "    environment= env,\n",
    "    \n",
    "    runtimes = {\n",
    "      # You can specify your OPENAI API KEY here via `OpenAIRuntime(..., api_key='your-api-key')`\n",
    "      'openai': OpenAIRuntime(\n",
    "        verbose=True,\n",
    "        api_key=settings.openai_api_key,\n",
    "        gpt_model_name=\"gpt-3.5-turbo\",\n",
    "        max_tokens=256,\n",
    "      )\n",
    "    },\n",
    "    default_runtime='openai',\n",
    "    \n",
    "    teacher_runtimes = {\n",
    "      'openai-gpt3': OpenAIRuntime(\n",
    "        verbose=True,\n",
    "        api_key=settings.openai_api_key,\n",
    "        gpt_model_name=\"gpt-3.5-turbo\",\n",
    "        max_tokens=256,\n",
    "        ),\n",
    "      'openai-gpt4': OpenAIRuntime(\n",
    "          verbose=True,\n",
    "          api_key=settings.openai_api_key,\n",
    "          gpt_model_name=\"gpt-4\",\n",
    "          max_tokens=256,\n",
    "        )\n",
    "    },\n",
    "    \n",
    "    # NOTE! If you don't have an access to gpt4 - replace it with \"openai-gpt3\"\n",
    "    default_teacher_runtime='openai-gpt3'\n",
    ")\n",
    "\n",
    "print(agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Agent\n",
    "\n",
    "We will now let Agent learn from the ground truth. After every action, Agent returns its _Experience_, where it stores various observations like predicted data, errors, accuracy, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.learn(learning_iterations=3, accuracy_threshold=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the final instructions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(agent.skills)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and predictions created by the skill:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.run(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying learned skills to the real data\n",
    "\n",
    "Now as we have our Agent with evolved \"subjectivity detection\" skill, we can apply it to the real dataset without ground truth data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame([\n",
    "    \"Doesn't hold charge.\",\n",
    "    \"Excellent bluetooth headset\",\n",
    "    \"I love this thing!\",\n",
    "    \"VERY DISAPPOINTED.\"\n",
    "], columns=['text'])\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = agent.run(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ally",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
